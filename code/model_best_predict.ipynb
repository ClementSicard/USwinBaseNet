{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "from utils import *\n",
                "from dataset import ImageDataset\n",
                "from models.swin_unet import SwinUNet\n",
                "from dataset import ImageDataset\n",
                "import os\n",
                "from glob import glob\n",
                "\n",
                "from tqdm import tqdm\n",
                "from utils import *\n",
                "from consts import *\n",
                "import cv2\n",
                "import numpy as np\n",
                "from datetime import datetime\n",
                "from PIL.Image import fromarray"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "checkpoint = torch.load(\"../checkpoints/omgggg.pt\", map_location=torch.device('cpu'))\n",
                "model = SwinUNet(model_type=\"base\").to(\"cpu\")\n",
                "model.load_state_dict(checkpoint[\"model_state_dict\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicting on test set...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading images: 100%|██████████| 144/144 [00:01<00:00, 101.30it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Resizing test images...\n"
                    ]
                }
            ],
            "source": [
                "device = \"cpu\"\n",
                "test_path = \"../data/test\"\n",
                "\n",
                "\n",
                "print(\"Predicting on test set...\")\n",
                "test_path = os.path.join(test_path, \"images\")\n",
                "test_filenames = glob(test_path + \"/*.png\")\n",
                "test_images = load_all_from_path(test_path)\n",
                "batch_size = test_images.shape[0]\n",
                "size = test_images.shape[1:3]\n",
                "# we also need to resize the test images. This might not be the best ideas depending on their spatial resolution.\n",
                "print(\"Resizing test images...\")\n",
                "test_images = np.stack([img for img in test_images], 0)\n",
                "test_images = test_images[:, :, :, :3]\n",
                "test_images = np_to_tensor(np.moveaxis(test_images, -1, 1), device)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Making predictions...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/144 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0.9938)\n",
                        "tensor(0.1962)\n",
                        "torch.Size([1, 1, 208, 208])\n",
                        "tensor(0.9805)\n",
                        "tensor(0.1960)\n",
                        "torch.Size([1, 1, 208, 208])\n",
                        "tensor(0.9956)\n",
                        "tensor(0.1971)\n",
                        "torch.Size([1, 1, 208, 208])\n",
                        "tensor(0.9919)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/144 [00:01<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor(0.1962)\n",
                        "torch.Size([1, 1, 208, 208])\n",
                        "Max of all pred cropeed images: 0.19710062444210052\n",
                        "Max full pred: 0.19604746997356415\n",
                        "Max full pred: 0.19604746997356415\n",
                        "Max full pred: 0.19701775908470154\n",
                        "Max full pred: 0.19701775908470154\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "ename": "Exception",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/Users/csicard/Documents/ETH/CI-Lab/code/model_best_predict.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/csicard/Documents/ETH/CI-Lab/code/model_best_predict.ipynb#ch0000003?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMax full pred: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmax(full_pred)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/csicard/Documents/ETH/CI-Lab/code/model_best_predict.ipynb#ch0000003?line=53'>54</a>\u001b[0m test_pred\u001b[39m.\u001b[39mappend(full_pred)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/csicard/Documents/ETH/CI-Lab/code/model_best_predict.ipynb#ch0000003?line=54'>55</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m()\n",
                        "\u001b[0;31mException\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "%matplotlib inline\n",
                "\n",
                "print(\"Making predictions...\")\n",
                "import torchvision.transforms.functional as TF\n",
                "\n",
                "\n",
                "# checkpoint = torch.load(best_weights_path)\n",
                "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
                "# print(f\"Loaded best model weights ({best_weights_path})\")\n",
                "\n",
                "test_pred = []\n",
                "CROP_SIZE = 200\n",
                "RESIZE_SIZE = 208\n",
                "for image in tqdm(test_images):\n",
                "    # 1. On fait les crops: on divise l'image en 4 parties qui ne s'overlapent pas\n",
                "    cropped_image = [\n",
                "        image[:, 0:CROP_SIZE, 0:CROP_SIZE],\n",
                "        image[:, CROP_SIZE : 2 * CROP_SIZE, 0:CROP_SIZE],\n",
                "        image[:, 0:CROP_SIZE, CROP_SIZE : 2 * CROP_SIZE],\n",
                "        image[:, CROP_SIZE : 2 * CROP_SIZE, CROP_SIZE : 2 * CROP_SIZE],\n",
                "    ]\n",
                "    pred_cropped = torch.zeros(len(cropped_image), 3, RESIZE_SIZE, RESIZE_SIZE)\n",
                "\n",
                "    for i, c_img in enumerate(cropped_image):\n",
                "        r = TF.resize(c_img, size=(RESIZE_SIZE, RESIZE_SIZE))[None, :]\n",
                "        print(torch.max(r))\n",
                "        res = model(r).detach().cpu()\n",
                "        print(torch.max(res))\n",
                "        print(res.shape)\n",
                "        \n",
                "        pred_cropped[i, :, :, :] = res\n",
                "\n",
                "\n",
                "    print(f\"Max of all pred cropeed images: {torch.max(pred_cropped)}\")\n",
                "\n",
                "    full_pred = np.zeros((3, 400, 400))\n",
                "\n",
                "    full_pred[:, 0:CROP_SIZE, 0:CROP_SIZE] = TF.resize(\n",
                "        pred_cropped[0], size=(CROP_SIZE, CROP_SIZE), antialias=True\n",
                "    )\n",
                "    print(f\"Max full pred: {np.max(full_pred)}\")\n",
                "    full_pred[:, CROP_SIZE : 2 * CROP_SIZE, 0:CROP_SIZE] = TF.resize(\n",
                "        pred_cropped[1], size=(CROP_SIZE, CROP_SIZE), antialias=True\n",
                "    )\n",
                "    print(f\"Max full pred: {np.max(full_pred)}\")\n",
                "    full_pred[:, 0:CROP_SIZE, CROP_SIZE : 2 * CROP_SIZE] = TF.resize(\n",
                "        pred_cropped[2], size=(CROP_SIZE, CROP_SIZE), antialias=True\n",
                "    )\n",
                "    print(f\"Max full pred: {np.max(full_pred)}\")\n",
                "    full_pred[\n",
                "        :, CROP_SIZE : 2 * CROP_SIZE, CROP_SIZE : 2 * CROP_SIZE\n",
                "    ] = TF.resize(pred_cropped[3], size=(CROP_SIZE, CROP_SIZE), antialias=True)\n",
                "    print(f\"Max full pred: {np.max(full_pred)}\")\n",
                "    test_pred.append(full_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "    print(\"max of test_pred\", np.max(test_pred))\n",
                "    # test_pred = [model(t).detach().cpu().numpy()\n",
                "    #              for t in tqdm(test_images.unsqueeze(1))]\n",
                "    test_pred = np.concatenate(test_pred, 0)\n",
                "    test_pred = np.moveaxis(test_pred, 1, -1)  # CHW to HWC\n",
                "    test_pred = np.stack([img for img in test_pred], 0)  # resize to original shape\n",
                "    # Now compute labels\n",
                "    test_pred = test_pred.reshape(\n",
                "        (-1, size[0] // PATCH_SIZE, PATCH_SIZE, size[0] // PATCH_SIZE, PATCH_SIZE)\n",
                "    )\n",
                "    test_pred = np.moveaxis(test_pred, 2, 3)\n",
                "    test_pred = np.round(np.mean(test_pred, (-1, -2)) > CUTOFF)\n",
                "    print(f\"Test predictions shape: {test_pred.shape}\")\n",
                "    now = datetime.now()\n",
                "    t = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
                "    os.makedirs(\"submissions\", exist_ok=True)\n",
                "    create_submission(\n",
                "        test_pred,\n",
                "        test_filenames,\n",
                "        submission_filename=f\"../submissions/swin_unet_submission_{t}.csv\",\n",
                "    )\n",
                "    print(f\"Created submission!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_pred_copy = test_pred.copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.max(test_pred[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "with torch.no_grad():\n",
                "    test_pred_c = np.concatenate(test_pred_copy, 0)\n",
                "    test_pred_c = np.moveaxis(test_pred, 1, -1)  # CHW to HWC\n",
                "    test_pred_c = np.stack([img for img in test_pred], 0)  # resize to original shape\n",
                "    # Now compute labels\n",
                "    test_pred_c = test_pred_c.reshape(\n",
                "        (-1, size[0] // PATCH_SIZE, PATCH_SIZE, size[0] // PATCH_SIZE, PATCH_SIZE)\n",
                "    )\n",
                "    test_pred_c = np.moveaxis(test_pred_c, 2, 3)\n",
                "    test_pred_c = np.round(np.mean(test_pred_c, (-1, -2)) > CUTOFF)\n",
                "    print(f\"Test predictions shape: {test_pred_c.shape}\")\n",
                "    now = datetime.now()\n",
                "    t = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
                "    os.makedirs(\"submissions\", exist_ok=True)\n",
                "    create_submission(\n",
                "        test_pred_c,\n",
                "        test_filenames,\n",
                "        submission_filename=f\"../submissions/swin_unet_submission_{t}.csv\",\n",
                "    )\n",
                "    print(f\"Created submission!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([2, 1, 2, 3])"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "a = torch.zeros((1,2, 3))\n",
                "b = torch.zeros((1,2, 3))\n",
                "c = torch.stack([a,b], 0)\n",
                "c.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([1, 2, 3])"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "c[0, :, :, :].shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[[0., 0., 0.],\n",
                        "         [0., 0., 0.]]])\n",
                        "tensor([[[0., 0., 0.],\n",
                        "         [0., 0., 0.]]])\n"
                    ]
                }
            ],
            "source": [
                "for i in c:\n",
                "    print(i)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 ('cil')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        },
        "vscode": {
            "interpreter": {
                "hash": "e94c46c399267a3102d21c0e97c5ee9fc91e71b8e548a3b77ef16a5ae53616e8"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
