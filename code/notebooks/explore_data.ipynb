{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_from_path(path: str):\n",
    "    # loads all HxW .pngs contained in path as a 4D np.array of shape (n_images, H, W, 3)\n",
    "    # images are loaded as floats with values in the interval [0., 1.]\n",
    "    return np.stack([np.array(Image.open(f)) for f in tqdm(sorted(glob(path + \"/*.png\")))]).astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "def show_first_n(imgs, masks, n=5):\n",
    "    # visualizes the first n elements of a series of images and segmentation masks\n",
    "    imgs_to_draw = min(n, len(imgs))\n",
    "    fig, axs = plt.subplots(2, imgs_to_draw, figsize=(18.5, 6))\n",
    "    for i in range(imgs_to_draw):\n",
    "        axs[0, i].imshow(imgs[i])\n",
    "        axs[1, i].imshow(masks[i])\n",
    "        axs[0, i].set_title(f\"Image {i}\")\n",
    "        axs[1, i].set_title(f\"Mask {i}\")\n",
    "        axs[0, i].set_axis_off()\n",
    "        axs[1, i].set_axis_off()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/training\"\n",
    "\n",
    "train_images = load_all_from_path(os.path.join(train_path, \"images\"))\n",
    "train_masks = load_all_from_path(os.path.join(train_path, \"groundtruth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_n(train_images, train_masks, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a PyTorch `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 16\n",
    "CUTOFF = 0.25\n",
    "\n",
    "def image_to_patches(images, masks=None):\n",
    "    # takes in a 4D np.array containing images and (optionally) a 4D np.array containing the segmentation masks\n",
    "    # returns a 4D np.array with an ordered sequence of patches extracted from the image and (optionally) a np.array containing labels\n",
    "    n_images = images.shape[0]  # number of images\n",
    "    h, w = images.shape[1:3]  # shape of images\n",
    "    assert (h % PATCH_SIZE) + (w % PATCH_SIZE) == 0  # make sure images can be patched exactly\n",
    "\n",
    "    images = images[:,:,:,:3]\n",
    "    \n",
    "    h_patches = h // PATCH_SIZE\n",
    "    w_patches = w // PATCH_SIZE\n",
    "    \n",
    "    patches = images.reshape((n_images, h_patches, PATCH_SIZE, w_patches, PATCH_SIZE, -1))\n",
    "    patches = np.moveaxis(patches, 2, 3)\n",
    "    patches = patches.reshape(-1, PATCH_SIZE, PATCH_SIZE, 3)\n",
    "    if masks is None:\n",
    "        return patches\n",
    "\n",
    "    masks = masks.reshape((n_images, h_patches, PATCH_SIZE, w_patches, PATCH_SIZE, -1))\n",
    "    masks = np.moveaxis(masks, 2, 3)\n",
    "    labels = np.mean(masks, (-1, -2, -3)) > CUTOFF  # compute labels\n",
    "    labels = labels.reshape(-1).astype(np.float32)\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def show_patched_image(patches, labels, h_patches=25, w_patches=25):\n",
    "    # reorders a set of patches in their original 2D shape and visualizes them\n",
    "    fig, axs = plt.subplots(h_patches, w_patches, figsize=(18.5, 18.5))\n",
    "    for i, (p, l) in enumerate(zip(patches, labels)):\n",
    "        # the np.maximum operation paints patches labeled as road red\n",
    "        axs[i // w_patches, i % w_patches].imshow(np.maximum(p, np.array([l.item(), 0., 0.])))\n",
    "        axs[i // w_patches, i % w_patches].set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_tensor(x, device):\n",
    "    # allocates tensors from np.arrays\n",
    "    if device == 'cpu':\n",
    "        return torch.from_numpy(x).cpu()\n",
    "    else:\n",
    "        return torch.from_numpy(x).contiguous().pin_memory().to(device=device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, device, use_patches=True, resize_to=(400, 400)):\n",
    "        self.path = path\n",
    "        self.device = device\n",
    "        self.use_patches = use_patches\n",
    "        self.resize_to = resize_to\n",
    "        self.x, self.y, self.n_samples = None, None, None\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):  # not very scalable, but good enough for now\n",
    "        self.x = load_all_from_path(os.path.join(self.path, 'images'))[:,:,:,:3]\n",
    "        self.y = load_all_from_path(os.path.join(self.path, 'groundtruth'))\n",
    "        if self.use_patches:  # split each image into patches\n",
    "            self.x, self.y = image_to_patches(self.x, self.y)\n",
    "        self.x = np.moveaxis(self.x, -1, 1)  # pytorch works with CHW format instead of HWC\n",
    "        self.n_samples = len(self.x)\n",
    "\n",
    "    def _preprocess(self, x, y):\n",
    "        # to keep things simple we will not apply transformations to each sample,\n",
    "        # but it would be a very good idea to look into preprocessing\n",
    "        return x, y\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self._preprocess(np_to_tensor(self.x[item], self.device), np_to_tensor(self.y[[item]], self.device))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baselines.baseline_vanilla_unet import UNet\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "train_path = \"../data/training/\"\n",
    "val_path = \"../data/validation/\"\n",
    "\n",
    "train_dataset = ImageDataset(train_path, device=device)\n",
    "val_dataset = ImageDataset(val_path, device=device)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cil')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e94c46c399267a3102d21c0e97c5ee9fc91e71b8e548a3b77ef16a5ae53616e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
