{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Dataset with Massachusetts roads dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Dataset kaggle link](https://www.kaggle.com/datasets/insaff/massachusetts-roads-dataset/download?datasetVersionNumber=1)\n",
    "\n",
    "The dataset is too big (~5 Go) so first we will only take an subset of it\n",
    "\n",
    "Click on the link to download the whole dataset, unzip it and place the folder ´road_segmentation_ideal´ in the directory ´data/´. Then, run the notebook to take only a cropped subset of the downloaded dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "import shutil\n",
    "from utils import *\n",
    "\n",
    "SUBSET_SIZE = 160\n",
    "DATA_DIR = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(DATA_DIR + 'road_segmentation_ideal/'):\n",
    "    print('please download the dataset and place it in the folder data/subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in_dst_dir = DATA_DIR +'road_segmentation_ideal_subset/training/input/'\n",
    "if not os.path.isdir(train_in_dst_dir):\n",
    "    os.makedirs(train_in_dst_dir)\n",
    "\n",
    "train_out_dst_dir = DATA_DIR + 'road_segmentation_ideal_subset/training/output/'\n",
    "if not os.path.isdir(train_out_dst_dir):\n",
    "    os.makedirs(train_out_dst_dir)\n",
    "\n",
    "outputs = os.listdir(DATA_DIR + 'road_segmentation_ideal/training/output/')\n",
    "random_elements = sample(outputs, SUBSET_SIZE)\n",
    "for name in random_elements :\n",
    "\n",
    "    train_in_src =  DATA_DIR +f'road_segmentation_ideal/training/input/{name}'\n",
    "    train_in_dst = train_in_dst_dir + f'{name}'\n",
    "    shutil.copy(train_in_src, train_in_dst)\n",
    "\n",
    "    train_out_src =  DATA_DIR +f'road_segmentation_ideal/training/output/{name}'\n",
    "    train_out_dst = train_out_dst_dir + f'{name}'\n",
    "    shutil.copy(train_out_src, train_out_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "test_src_dir = DATA_DIR + 'road_segmentation_ideal/testing/'\n",
    "test_dst_dir = DATA_DIR + 'road_segmentation_ideal_subset/testing/'\n",
    "\n",
    "test_dst_in_dir = test_dst_dir + 'input'\n",
    "if not os.path.isdir(test_dst_in_dir):\n",
    "    os.makedirs(test_dst_in_dir)\n",
    "\n",
    "test_dst_out_dir = test_dst_dir + 'output'\n",
    "if not os.path.isdir(test_dst_out_dir):\n",
    "    os.makedirs(test_dst_out_dir)\n",
    "\n",
    "copy_tree(test_src_dir, test_dst_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = load_all_from_path(train_in_dst_dir)\n",
    "# masks = load_all_from_path(train_out_dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_first_n(images, masks, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that images from Massachusetts dataset are (1500x1500) so we will randomly crop them so they are (400x400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "CROP_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_directory = DATA_DIR + 'road_segmentation_ideal_subset_cropped/'\n",
    "if not os.path.isdir(cropped_directory):\n",
    "    os.mkdir(cropped_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop training images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crop_out_dst_dir = cropped_directory + 'training/output/'\n",
    "if not os.path.isdir(train_crop_out_dst_dir):\n",
    "    os.makedirs(train_crop_out_dst_dir)\n",
    "\n",
    "train_crop_in_dst_dir = cropped_directory + 'training/input/'\n",
    "if not os.path.isdir(train_crop_in_dst_dir):\n",
    "    os.makedirs(train_crop_in_dst_dir)\n",
    "    \n",
    "for name in os.listdir(DATA_DIR + 'road_segmentation_ideal_subset/training/output/'):\n",
    "    image = Image.open(train_in_dst_dir + f'{name}')\n",
    "    mask = Image.open(train_out_dst_dir + f'{name}')\n",
    "    transform = transforms.RandomCrop(CROP_SIZE)\n",
    "    i, j, h, w = transform.get_params(image, output_size=(CROP_SIZE, CROP_SIZE))\n",
    "    image_crop = TF.crop(image, i, j, h, w)\n",
    "    mask_crop = TF.crop(mask, i, j, h, w)\n",
    "    image_crop.save(train_crop_in_dst_dir + f'{name}')\n",
    "    mask_crop.save(train_crop_out_dst_dir + f'{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_crop_in_dir = cropped_directory + 'testing/input/'\n",
    "if not os.path.isdir(test_crop_in_dir):\n",
    "    os.makedirs(test_crop_in_dir)\n",
    "\n",
    "test_crop_out_dir = cropped_directory + 'testing/output/'\n",
    "if not os.path.isdir(test_crop_out_dir):\n",
    "    os.makedirs(test_crop_out_dir)\n",
    "\n",
    "test_out_dst_dir = DATA_DIR + 'road_segmentation_ideal_subset/testing/output/'\n",
    "test_in_dst_dir = DATA_DIR + 'road_segmentation_ideal_subset/testing/input/'\n",
    "for name in os.listdir(test_out_dst_dir):\n",
    "    image = Image.open(test_in_dst_dir + f'{name}')\n",
    "    mask = Image.open(test_out_dst_dir + f'{name}')\n",
    "    transform = transforms.RandomCrop(CROP_SIZE)\n",
    "    i, j, h, w = transform.get_params(image, output_size=(CROP_SIZE, CROP_SIZE))\n",
    "    image_crop = TF.crop(image, i, j, h, w)\n",
    "    mask_crop = TF.crop(mask, i, j, h, w)\n",
    "    image_crop.save(test_crop_in_dir + f'{name}')\n",
    "    mask_crop.save(test_crop_out_dir + f'{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have create the cropped subset, we can delete the subset directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dir = DATA_DIR + 'road_segmentation_ideal_subset/'\n",
    "if os.path.isdir(subset_dir):\n",
    "    shutil.rmtree(subset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split the cropped train directory into training and validation\n",
    "We do so by taking at random 10 elements of the training set and putting them into validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = int(SUBSET_SIZE * 30 / 100)\n",
    "\n",
    "val_dir = DATA_DIR + 'road_segmentation_ideal_subset_cropped/validation/'\n",
    "if not os.path.isdir(val_dir):\n",
    "    os.mkdir(val_dir)\n",
    "\n",
    "val_dir_in = val_dir + 'input/'\n",
    "if not os.path.isdir(val_dir_in):\n",
    "    os.mkdir(val_dir_in)\n",
    "\n",
    "val_dir_out = val_dir + 'output/'\n",
    "if not os.path.isdir(val_dir_out):\n",
    "    os.mkdir(val_dir_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in_dir = DATA_DIR + 'road_segmentation_ideal_subset_cropped/training/input/'\n",
    "train_out_dir = DATA_DIR + 'road_segmentation_ideal_subset_cropped/training/output/'\n",
    "\n",
    "train_elements = os.listdir(train_in_dir)\n",
    "rdm_val_elements = sample(train_elements, VALIDATION_SIZE)\n",
    "for val_el in rdm_val_elements:\n",
    "    shutil.move(train_in_dir + val_el, val_dir_in + val_el)\n",
    "    shutil.move(train_out_dir + val_el, val_dir_out + val_el)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cil')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "362d7b76c41f386abdf9d564d30c7d8055f120fb8664ae4a13ab7f7fc06717b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
